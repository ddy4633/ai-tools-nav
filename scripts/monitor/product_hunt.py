#!/usr/bin/env python3
"""
Product Hunt ç›‘æ§è„šæœ¬
æ¯å°æ—¶æŠ“å– AI åˆ†ç±»çš„æ–°å“ï¼Œç­›é€‰å‡ºæœ‰ä»·å€¼çš„å·¥å…·
"""

import requests
import json
import os
from datetime import datetime, timedelta
from typing import List, Dict, Optional

# é…ç½®
SUPABASE_URL = os.getenv('SUPABASE_URL', '')
SUPABASE_KEY = os.getenv('SUPABASE_SERVICE_KEY', '')
MIN_VOTES = 50  # æœ€å°ç‚¹èµæ•°
MIN_AGE_HOURS = 48  # æœ€å¤§å¹´é¾„ï¼ˆå°æ—¶ï¼‰

def fetch_product_hunt_posts() -> List[Dict]:
    """è·å– Product Hunt æœ€æ–°å¸–å­"""
    # ä½¿ç”¨ Product Hunt GraphQL API
    # æ³¨æ„ï¼šå®é™…ä½¿ç”¨éœ€è¦ API Token
    query = """
    {
      posts(first: 20, postedAfter: "{date}") {
        edges {
          node {
            id
            name
            tagline
            description
            url
            website
            thumbnail {
              url
            }
            votesCount
            commentsCount
            createdAt
            topics {
              edges {
                node {
                  name
                }
              }
            }
            makers {
              name
              twitterUsername
            }
          }
        }
      }
    }
    """.format(date=(datetime.now() - timedelta(hours=MIN_AGE_HOURS)).isoformat())
    
    # è¿™é‡Œä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®æ¼”ç¤ºç»“æ„
    # å®é™…éƒ¨ç½²æ—¶éœ€è¦æ›¿æ¢ä¸ºçœŸå® API è°ƒç”¨
    mock_posts = [
        {
            "id": "mock-1",
            "name": "AI Code Reviewer",
            "tagline": "Automated code reviews using AI",
            "description": "Get instant code reviews on every PR with AI-powered suggestions.",
            "url": "https://www.producthunt.com/posts/ai-code-reviewer",
            "website": "https://aicodereview.com",
            "thumbnail": {"url": "https://example.com/icon.png"},
            "votesCount": 120,
            "commentsCount": 25,
            "createdAt": datetime.now().isoformat(),
            "topics": [{"node": {"name": "AI"}}, {"node": {"name": "Developer Tools"}}],
            "makers": [{"name": "John Doe", "twitterUsername": "johndoe"}]
        }
    ]
    
    return mock_posts

def calculate_viral_score(post: Dict) -> float:
    """è®¡ç®—çƒ­åº¦å¾—åˆ†"""
    votes = post.get('votesCount', 0)
    comments = post.get('commentsCount', 0)
    
    # åŸºç¡€å¾—åˆ†
    score = min(votes / 100, 10) + min(comments / 20, 5)
    
    # æ—¶æ•ˆåŠ åˆ†ï¼ˆ24å°æ—¶å†…ï¼‰
    created = datetime.fromisoformat(post['createdAt'].replace('Z', '+00:00'))
    hours_old = (datetime.now() - created).total_seconds() / 3600
    if hours_old <= 24:
        score += 10
    elif hours_old <= 48:
        score += 5
    
    return score

def is_ai_related(post: Dict) -> bool:
    """åˆ¤æ–­æ˜¯å¦ AI ç›¸å…³"""
    ai_keywords = ['ai', 'artificial intelligence', 'machine learning', 'llm', 'gpt', 'chatbot', 'automation']
    
    text = f"{post.get('name', '')} {post.get('tagline', '')} {post.get('description', '')}".lower()
    
    # æ£€æŸ¥ topics
    topics = [t['node']['name'].lower() for t in post.get('topics', {}).get('edges', [])]
    
    return any(kw in text or kw in ' '.join(topics) for kw in ai_keywords)

def should_track(post: Dict) -> bool:
    """åˆ¤æ–­æ˜¯å¦å€¼å¾—è¿½è¸ª"""
    # åŸºæœ¬æ¡ä»¶
    if post.get('votesCount', 0) < MIN_VOTES:
        return False
    
    # å¿…é¡»æ˜¯ AI ç›¸å…³
    if not is_ai_related(post):
        return False
    
    # è®¡ç®—å¾—åˆ†
    score = calculate_viral_score(post)
    return score >= 15

def save_to_supabase(posts: List[Dict]):
    """ä¿å­˜åˆ° Supabase"""
    if not SUPABASE_URL or not SUPABASE_KEY:
        print("âš ï¸ Supabase credentials not set, skipping database save")
        return
    
    headers = {
        'apikey': SUPABASE_KEY,
        'Authorization': f'Bearer {SUPABASE_KEY}',
        'Content-Type': 'application/json'
    }
    
    for post in posts:
        data = {
            'name': post['name'],
            'tagline': post['tagline'],
            'description': post.get('description', ''),
            'website': post.get('website', post['url']),
            'icon': post.get('thumbnail', {}).get('url', ''),
            'source': 'product-hunt',
            'source_url': post['url'],
            'viral_score': calculate_viral_score(post),
            'social_metrics': {
                'productHunt': {
                    'votes': post.get('votesCount', 0),
                    'comments': post.get('commentsCount', 0)
                }
            },
            'status': 'discovered',
            'discovered_at': datetime.now().isoformat(),
            'source_posted_at': post['createdAt']
        }
        
        try:
            response = requests.post(
                f"{SUPABASE_URL}/rest/v1/tools",
                headers=headers,
                json=data
            )
            if response.status_code == 201:
                print(f"âœ… Saved: {post['name']}")
            else:
                print(f"âŒ Failed to save {post['name']}: {response.text}")
        except Exception as e:
            print(f"âŒ Error saving {post['name']}: {e}")

def main():
    print(f"ğŸ” Starting Product Hunt monitor at {datetime.now()}")
    
    # è·å–å¸–å­
    posts = fetch_product_hunt_posts()
    print(f"ğŸ“Š Found {len(posts)} posts in last {MIN_AGE_HOURS}h")
    
    # ç­›é€‰
    tracked_posts = [p for p in posts if should_track(p)]
    print(f"â­ {len(tracked_posts)} posts worth tracking")
    
    # æŒ‰å¾—åˆ†æ’åº
    tracked_posts.sort(key=calculate_viral_score, reverse=True)
    
    # æ‰“å°ç»“æœ
    for post in tracked_posts:
        score = calculate_viral_score(post)
        print(f"\n[{score:.1f}] {post['name']}")
        print(f"    {post['tagline']}")
        print(f"    ğŸ‘ {post.get('votesCount', 0)} ğŸ’¬ {post.get('commentsCount', 0)}")
        print(f"    ğŸ”— {post.get('website', post['url'])}")
    
    # ä¿å­˜åˆ°æ•°æ®åº“
    save_to_supabase(tracked_posts)
    
    print(f"\nâœ… Monitor completed at {datetime.now()}")

if __name__ == '__main__':
    main()
